{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "#sys.path.append('/home/elgutto/Documents/masters/goexplore/atari/lib/python3.8/site-packages')\n",
    "import gym\n",
    "import json\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = len(self) - 1 = 2244\n",
      "len(self): 2245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Demonstration(score: 21.0, timesteps: 2245, env: PongDeterministic-v4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Demonstration:\n",
    "    def __init__(self, experiences, env):\n",
    "        self.experiences = experiences\n",
    "        self.env = env\n",
    "        self.starting_point = len(self) - 1\n",
    "        \n",
    "    def restore(self, i):\n",
    "        state = self.experiences[i].state\n",
    "        self.env.unwrapped.restore_state(state) # env as parameter?\n",
    "        return state\n",
    "    \n",
    "    def reward(self, i):\n",
    "        return self.experiences[i].reward\n",
    "    \n",
    "    def score(self, i):\n",
    "        return self.experiences[i].score\n",
    "    \n",
    "    def action(self, i):\n",
    "        return self.experiences[i].action\n",
    "    \n",
    "    def is_lagging(self, score, i, L):\n",
    "        window = self.experiences[i - L, i + L + 1]\n",
    "        window_scores = [experience.score for experience in window]\n",
    "        return score < min(window_scores)\n",
    "    \n",
    "    def update_starting_point(self, starting_point):\n",
    "        self.starting_point = starting_point\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.experiences)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return len(self) == len(other)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return len(self) < len(other)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f'Demonstration(score: {self.score(len(self)-1)}, '\n",
    "                              f'timesteps: {len(self)}, '\n",
    "                              f'env: {self.env.unwrapped.spec.id})')\n",
    "    \n",
    "def read_actions(json_file):\n",
    "    with open(json_file) as f:\n",
    "        d = json.load(f)\n",
    "        return d['actions_taken']\n",
    "    \n",
    "Experience = namedtuple('Experience', 'state action reward done score')\n",
    "def demo_from_actions(actions, env):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    experiences = []\n",
    "    score = 0\n",
    "    for action in actions:\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        score += reward\n",
    "        experiences.append(Experience(state, action, reward, done, score))\n",
    "        if done: break\n",
    "    demonstration = Demonstration(experiences, env)\n",
    "    return demonstration\n",
    "\n",
    "p = Path('explore/experiments/2021-12-13-13:29:34_demos4M').glob('*')\n",
    "files = [x for x in p if x.is_file()]\n",
    "demonstrations = []\n",
    "for file in files:\n",
    "    env = gym.make('PongDeterministic-v4')\n",
    "    actions = read_actions(file)\n",
    "    demonstrations.append(demo_from_actions(actions, env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = sorted(demonstrations)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Demonstration(score: 21.0, timesteps: 2245, env: PongDeterministic-v4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = 870\n",
    "D = 1\n",
    "import numpy as np\n",
    "np.random.choice([sp - i for i in range(D)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single demo\n",
    "\n",
    "K = 800\n",
    "L = 128 # Batch size I guess?\n",
    "delta = 100\n",
    "env = gym.make('PongDeterministic-v4')\n",
    "starting_point = demo.starting_point\n",
    "D = 1\n",
    "candidate_start_points = [starting_point - i for i in range(D)]\n",
    "tau = np.random.choice(candidate_starting_points)\n",
    "score = demo.score(tau)\n",
    "state = demo.restore(tau)\n",
    "i = tau - K\n",
    "\n",
    "while True: #for _ in range(1000000)\n",
    "    policy = optimizer.policy()\n",
    "    starting_point = optimizer.starting_point()\n",
    "    W = False\n",
    "    D = []\n",
    "    \n",
    "    for _ in range(L): #?\n",
    "        if i >= tau:\n",
    "            action = policy(state)\n",
    "            mask = True\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "        else:\n",
    "            state = demo.restore(i)\n",
    "            action = demo.action(i)\n",
    "            reward = demo.reward(i)\n",
    "            next_state = demo.state(i + 1)\n",
    "            done = demo.done(i)\n",
    "            mask = False\n",
    "        \n",
    "        D.append((state, action, reward, next_state, done, mask))\n",
    "        i += 1\n",
    "        \n",
    "        if done:\n",
    "            #W = True if score >= demo.score(i) # Push back as soon as it completes\n",
    "            if score >= demo.score(i):\n",
    "                demo.update_starting_point(demo.starting_point - delta)\n",
    "            starting_point = demo.starting_point\n",
    "            candidate_start_points = [starting_point - i for i in range(D)]\n",
    "            tau = np.random.choice(candidate_starting_points)\n",
    "            score = demo.score(tau)\n",
    "            i = tau - K\n",
    "            demo.restore(tau)\n",
    "    optimizer.optimize(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('PongDeterministic-v4')\n",
    "S_demo = 3 # Current starting state index for demo; zero or none I think, start_frame or starting_points\n",
    "L = 50 # Allowed lag\n",
    "K = 800 # Steps to initialize RNN state K (800? ffmemsize?)\n",
    "C = 7 # Extra frames coefficient \n",
    "policy = lambda state: np.random.randint(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-dc055d9b1aab>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-dc055d9b1aab>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    w_demo =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "frame_counts_demo = []\n",
    "frame_counts_virtual = []\n",
    "done = True\n",
    "while true:\n",
    "    if done:\n",
    "        w_demo = len(demonstrations) / np.mean(frame_counts_demo) if frame_counts_demo else 1\n",
    "        w_virtual = 1 / np.mean(frame_counts_virtual) if frame_counts_virtual else 1\n",
    "        p_virtual = w_virtual / (w_demo + w_virtual)\n",
    "        \n",
    "        if np.random.rand() < p_virtual:\n",
    "            demo = None\n",
    "            i = 0\n",
    "            state = env.reset()\n",
    "        else:\n",
    "            demo = np.random.choice(demonstrations)\n",
    "            i = max(0, demo.starting_point - K)\n",
    "            state = demo.restore(i)\n",
    "            score = demo.score(i)\n",
    "            remaining_frame_count = len(demo) - i + np.exp(C * np.random.rand())\n",
    "            \n",
    "    if demo is None or i >= demo.starting_point: # Act according to policy if virtual demo or past starting point\n",
    "        action = policy(state)\n",
    "        mask = True\n",
    "        next_state, reward, done, _ = env.step(action) # Replay transitions can not be stochastic\n",
    "    else:\n",
    "        action = demo.action(i)\n",
    "        reward = demo.reward(i)\n",
    "        mask = False\n",
    "    data = (state, action, reward, next_state, done, mask)\n",
    "    optimizer(data)\n",
    "    \n",
    "    if demo is not None and not done:\n",
    "        remaining_frame_count = remaining_frame_count - 1\n",
    "        done = remaining_frame_count < 0 or demo.is_lagging(score, i, L)\n",
    "    i += 1\n",
    "    \n",
    "    if done and demo is not None:\n",
    "        frame_counts_demo.append(i - max(0, demo.starting_point - K))\n",
    "        success = True if score >= demo.score(len(demo) - 1) else False\n",
    "    else if done:\n",
    "        frame_counts_virtual.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.array([1, 2, 3])\n",
    "l.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'insert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4928ed56af76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'insert'"
     ]
    }
   ],
   "source": [
    "l.insert(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(l, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1, 2, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Atari",
   "language": "python",
   "name": "atari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
